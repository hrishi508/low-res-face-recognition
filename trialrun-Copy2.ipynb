{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation, Input #changed 'keras.' to 'tensorflow.keras.'\n",
    "from tensorflow.keras.models import Sequential, Model #changed 'keras.' to 'tensorflow.keras.'\n",
    "from tensorflow.keras import optimizers #changed 'keras.' to 'tensorflow.keras.'\n",
    "import cv2\n",
    "import math\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import Sequential\n",
    "from IPython.display import display\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import sys\n",
    "from keras.models import load_model\n",
    "import mtcnn\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import keras\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import resnet\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "target_shape = (160, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vggface_vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc6/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "fc7/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 2622)              10742334  \n",
      "_________________________________________________________________\n",
      "fc8/softmax (Activation)     (None, 2622)              0         \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGGFace()\n",
    "model.summary()\n",
    "#weight = model.get_weights()\n",
    "#print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Sequential()\n",
    "for layer in model.layers[0:-4]: # just exclude last two layers from copying\n",
    "    temp.add(layer)\n",
    "\n",
    "for layer in temp.layers[0:9]:\n",
    "    layer.trainable = False\n",
    "#temp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "directory = \"finaltrain\"\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory, label_mode=None, color_mode='rgb', batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=True, seed=0, validation_split=None, subset=None,\n",
    "    interpolation='bicubic', follow_links=False)\n",
    "directory = \"newval\"\n",
    "valid_ds = image_dataset_from_directory(\n",
    "    directory, label_mode=None, color_mode='rgb', batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=True, seed=0, validation_split=None, subset=None,\n",
    "    interpolation='bicubic', follow_links=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(160,160,3))\n",
    "C1 = Conv2D(96,(9,9),padding='SAME',name='CONV1')(input_img)\n",
    "A1 = Activation('relu', name='act1')(C1)\n",
    "C2 = Conv2D(64,(1,1),padding='SAME',name='CONV2')(A1)\n",
    "A2 = Activation('relu', name='act2')(C2)\n",
    "C3 = Conv2D(48,(1,1),padding='SAME',name='CONV3')(A2)\n",
    "A3 = Activation('relu', name='act3')(C3)\n",
    "C4 = Conv2D(32,(1,1),padding='SAME',name='CONV4')(A3)\n",
    "A4 = Activation('relu', name='act4')(C4)\n",
    "C5 = Conv2D(3,(5,5),padding='SAME',name='CONV5')(A4)\n",
    "A5 = Activation('relu', name='act5')(C5)\n",
    "SR = Model(input_img, A5)\n",
    "opt = optimizers.Adam(learning_rate = 0.00001)\n",
    "SR.compile(optimizer=opt,loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SR = keras.models.load_model('Models/SR/SRnet')\n",
    "#SR.load_weights('Models/SR/epoch101-110/SRnetweights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 160, 160, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 224, 224, 3).\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 160, 160, 3)       36723     \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 4096)              117479232 \n",
      "=================================================================\n",
      "Total params: 117,515,955\n",
      "Trainable params: 115,743,744\n",
      "Non-trainable params: 1,772,211\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=7,\n",
    "                              verbose=0, mode='min', restore_best_weights=False)'''\n",
    "\n",
    "input_img = Input(shape=(224,224,3))\n",
    "A5 = SR(input_img) \n",
    "A6 = temp(A5)\n",
    "SRFECNN = Model(input_img, A6)\n",
    "opt = optimizers.Adam(learning_rate = 0.0000008)\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "    \n",
    "SRFECNN.compile(\n",
    "    optimizer=opt,\n",
    "    loss=root_mean_squared_error,\n",
    "    metrics=['accuracy'])\n",
    "for layer in SRFECNN.layers[0:-1]:\n",
    "    layer.trainable = False\n",
    "#SRFECNN.load_weights('Models/twobranch/twobranch_weights_e1_rms.h5')\n",
    "#SRFECNN.compile(optimizer=opt,loss='root_mean_squared_error',metrics=['accuracy'])\n",
    "SRFECNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FECNN = Sequential()\n",
    "for layer in model.layers[0:-2]: # just exclude last two layers from copying\n",
    "    FECNN.add(layer)\n",
    "for layer in FECNN.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#weights = FECNN.get_weights()\n",
    "#print(weights)\n",
    "#FECNN.save('Models/FECNN')\n",
    "FECNN.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate training images, we first need to downscale the image by scaler factor and then upscale it back to the original size\n",
    "def create_LR(image): \n",
    "    image = image / 255 #normalising the pixel values\n",
    "    image = tf.image.resize(image, [24, 24], method=\"bicubic\") #for 36x35, batches~75, loss~4000, accuracy~62\n",
    "    image = tf.image.resize(image, [224, 224], method=\"bicubic\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.map(\n",
    "    lambda x: (create_LR(x), FECNN(x))\n",
    ")\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#valid_ds = valid_ds.map(\n",
    "#    lambda x: (create_LR(x), FECNN(x))\n",
    "#)\n",
    "#valid_ds = valid_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRFECNN.load_weights('Models/twobranch_overfit/final2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "history = SRFECNN.fit(train_ds, epochs=20)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SRFECNN.save('Models/SRFECNN')\n",
    "#SRFECNN.save('Models/twobranch/twobranch_weights_e1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRFECNN.save('Models/twobranch_overfit/final2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict()\n",
    "i=0\n",
    "TP = 0\n",
    "\n",
    "for filename in os.listdir('finaltrain/finaltrain'):\n",
    "    img = cv2.imread(os.path.join('finaltrain/finaltrain',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imgr = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    imgr = np.array([imgr])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec = FECNN.predict(imgr)\n",
    "    vec = vec.flatten()\n",
    "    dic['s'+ str(i)] = vec\n",
    "    i = i+1\n",
    "#print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "i=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0\n",
    "accuracy = 0\n",
    "t=7.5\n",
    "b=0\n",
    "b = []\n",
    "for filename in os.listdir('finaltest/test'):\n",
    "    img = cv2.imread(os.path.join('finaltest/test',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    img1 = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    imgr = np.array([img1])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec1 = SRFECNN.predict(imgr)\n",
    "    vec1 = vec1.flatten()\n",
    "    #print(vec1)\n",
    "    vec1 = vec1/np.linalg.norm(vec1)\n",
    "    a=[]\n",
    "    for j in range(100):\n",
    "        k = 's' + str(j)\n",
    "        vec2 = dic[k]/np.linalg.norm(dic[k])\n",
    "        dist = np.linalg.norm(vec2-vec1)\n",
    "        dist = dist.flatten()\n",
    "        a.append(dist)\n",
    "    b.append(min(a))\n",
    "'''if(dist.numpy()<=5 and j==int(i/5)):\n",
    "            TP = TP + 1\n",
    "            accuracy = accuracy + 1\n",
    "        elif(dist.numpy()<=5 and j!=int(i/5)): \n",
    "            FP = FP + 1\n",
    "        \n",
    "        #print(\"dist = \",dist,\"subject = \",j,\"i = \",i)\n",
    "    temp = max(a)\n",
    "    #print(temp)\n",
    "    if(temp.numpy()<t):\n",
    "        if(i<50):\n",
    "            b-=1\n",
    "        accuracy+=1\n",
    "    i = i+1\n",
    "print(accuracy)\n",
    "print(b)\n",
    "\n",
    "P = TP/(TP+FP)\n",
    "R = TP/(TP+FN)\n",
    "F1 = 2*P*R/(P+R)\n",
    "print(P) 0.76\n",
    "print((accuracy/500)*100)\n",
    "end = time.time()\n",
    "print(end - start)'''\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "kmean = KMeans(n_clusters=2)\n",
    "labels = kmean.fit_predict(b)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_1=[]\n",
    "labels_0=[]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i]==1):\n",
    "        labels_1.append(b[i])\n",
    "    else:\n",
    "        labels_0.append(b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_1)\n",
    "print(labels_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(0,1)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Image number', fontsize = 15)\n",
    "ax.set_ylabel('Distance', fontsize = 15)\n",
    "ax.set_title('KMeans clustering', fontsize = 20)\n",
    "ax.scatter(range(0,40),labels_0,color='red')\n",
    "ax.scatter(range(40,66),labels_1,color='blue')\n",
    "ax.scatter([20,53],[[0.37287224],\n",
    "       [0.11982424]],marker='x',linewidths=3,color='purple')\n",
    "ax.plot([0,66],[0.235,0.235],color='green')\n",
    "ax.legend(['Threshold','Img not in DB','Img in DB','Cluster centroids'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b[:40]\n",
    "mini = min(c)\n",
    "#print(mini)\n",
    "d = b[40:]\n",
    "maxi = max(d)\n",
    "#print(c) maximum = 0.23314758\n",
    "print(d) #minimum = 0.23771875,0.25001103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "start = time.time()\n",
    "i=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0\n",
    "accuracy = 0\n",
    "t=7.5\n",
    "b=0\n",
    "x = []\n",
    "\n",
    "'''img = cv2.imread(os.path.join('finaltrain/train',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imgr = np.array([img])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec = FECNN.predict(imgr)'''\n",
    "    \n",
    "for filename in os.listdir('finaltrain/finaltrain'):\n",
    "    img = cv2.imread(os.path.join('finaltrain/finaltrain',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    imgr = np.array([img])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec = SRFECNN.predict(imgr)\n",
    "    \n",
    "    #print(vec)\n",
    "    x.append(vec.flatten())\n",
    "    #vec1 = vec1/np.linalg.norm(vec1)\n",
    "    #a = []\n",
    "    '''for j in range(50):\n",
    "        k = 's' + str(j)\n",
    "        vec2 = dic[k]/np.linalg.norm(dic[k])\n",
    "        dist = tf.reduce_sum(K.sqrt(K.square(vec2-vec1)))\n",
    "        a.append(dist)'''  \n",
    "#print(x)\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "colors = ['r', 'g', 'b','c','m','y','k','gold','grey','purple']\n",
    "k=[0,2,6,8,9]\n",
    "for i in range(10):\n",
    "    ax.scatter(principalDf.loc[range((i*10),((i*10)+10)), 'principal component 1']\n",
    "               , principalDf.loc[range((i*10),((i*10)+10)), 'principal component 2']\n",
    "               , c = colors[i]\n",
    "               , s = 50)\n",
    "#ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsal\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1059: UserWarning: inception_resnet_v1 is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  warnings.warn('{} is not loaded, but a Lambda layer uses it. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"inception_resnet_v1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 17, 17, 256)  0           Block35_1_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Activation (Activatio (None, 17, 17, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 17, 17, 256)  0           Block35_2_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Activation (Activatio (None, 17, 17, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 17, 17, 256)  0           Block35_3_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Activation (Activatio (None, 17, 17, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 17, 17, 256)  0           Block35_4_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Activation (Activatio (None, 17, 17, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 17, 17, 256)  0           Block35_5_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Activation (Activatio (None, 17, 17, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 8, 8, 896)    0           Block17_1_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Activation (Activatio (None, 8, 8, 896)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 8, 8, 896)    0           Block17_2_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Activation (Activatio (None, 8, 8, 896)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_3_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_3_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_3_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_3_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_3_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 8, 8, 896)    0           Block17_3_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 896)    0           Block17_2_Activation[0][0]       \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Activation (Activatio (None, 8, 8, 896)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_4_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_4_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_4_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_4_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_4_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 8, 8, 896)    0           Block17_4_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 896)    0           Block17_3_Activation[0][0]       \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Activation (Activatio (None, 8, 8, 896)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_5_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_5_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_5_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_5_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_5_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 8, 8, 896)    0           Block17_5_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 896)    0           Block17_4_Activation[0][0]       \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Activation (Activatio (None, 8, 8, 896)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_6_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_6_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_6_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_6_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_6_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 8, 8, 896)    0           Block17_6_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 896)    0           Block17_5_Activation[0][0]       \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Activation (Activatio (None, 8, 8, 896)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_7_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_7_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_7_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_7_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_7_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 8, 8, 896)    0           Block17_7_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 896)    0           Block17_6_Activation[0][0]       \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Activation (Activatio (None, 8, 8, 896)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_8_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_8_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_8_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_8_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_8_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 8, 8, 896)    0           Block17_8_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 896)    0           Block17_7_Activation[0][0]       \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Activation (Activatio (None, 8, 8, 896)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_9_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_9_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_9_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_9_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_9_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 8, 8, 896)    0           Block17_9_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 896)    0           Block17_8_Activation[0][0]       \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Activation (Activatio (None, 8, 8, 896)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    384         Block17_10_Branch_0_Conv2d_1x1[0]\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    0           Block17_10_Branch_0_Conv2d_1x1_Ba\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Concatenate (Concate (None, 8, 8, 256)    0           Block17_10_Branch_0_Conv2d_1x1_Ac\n",
      "                                                                 Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      Block17_10_Concatenate[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 8, 8, 896)    0           Block17_10_Conv2d_1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 896)    0           Block17_9_Activation[0][0]       \n",
      "                                                                 lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Activation (Activati (None, 8, 8, 896)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    589824      Mixed_7a_Branch_2_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_0_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0b_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_0_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0b_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    884736      Mixed_7a_Branch_0_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_2_Conv2d_0b_3x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    1152        Mixed_7a_Branch_0_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_1_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_2_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    0           Mixed_7a_Branch_0_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_1_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_2_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_3_MaxPool_1a_3x (None, 3, 3, 896)    0           Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a (Concatenate)          (None, 3, 3, 1792)   0           Mixed_7a_Branch_0_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_1_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_2_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_3_MaxPool_1a_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_1_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_1_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_1_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_1_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_1_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 3, 3, 1792)   0           Block8_1_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 3, 3, 1792)   0           Mixed_7a[0][0]                   \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Activation (Activation (None, 3, 3, 1792)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_2_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_2_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_2_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_2_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_2_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 3, 3, 1792)   0           Block8_2_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 3, 3, 1792)   0           Block8_1_Activation[0][0]        \n",
      "                                                                 lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Activation (Activation (None, 3, 3, 1792)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_3_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_3_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_3_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_3_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_3_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 3, 3, 1792)   0           Block8_3_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 3, 3, 1792)   0           Block8_2_Activation[0][0]        \n",
      "                                                                 lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Activation (Activation (None, 3, 3, 1792)   0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_4_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_4_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_4_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_4_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_4_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 3, 3, 1792)   0           Block8_4_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 3, 3, 1792)   0           Block8_3_Activation[0][0]        \n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Activation (Activation (None, 3, 3, 1792)   0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_5_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_5_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_5_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_5_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_5_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 3, 3, 1792)   0           Block8_5_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 3, 3, 1792)   0           Block8_4_Activation[0][0]        \n",
      "                                                                 lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Activation (Activation (None, 3, 3, 1792)   0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_6_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_6_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_6_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_6_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_6_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 3, 3, 1792)   0           Block8_6_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 3, 3, 1792)   0           Block8_5_Activation[0][0]        \n",
      "                                                                 lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (GlobalAveragePooling2D (None, 1792)         0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Dropout (Dropout)               (None, 1792)         0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck (Dense)              (None, 512)          917504      Dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_BatchNorm (BatchNorm (None, 512)          1536        Bottleneck[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,497,424\n",
      "Trainable params: 23,467,824\n",
      "Non-trainable params: 29,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.models.load_model('keras-facenet-master/keras-facenet-master/model/keras/model/facenet_keras.h5')\n",
    "model1.load_weights('weights.h5')\n",
    "#for layer in model1.layers:\n",
    "#    layer.trainable = False\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGFace()\n",
    "embedding = Sequential()\n",
    "for layer in model.layers[0:-2]: # just exclude last two layers from copying\n",
    "    embedding.add(layer)\n",
    "embedding.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "start = time.time()\n",
    "i=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0\n",
    "accuracy = 0\n",
    "t=7.5\n",
    "b=0\n",
    "x = []\n",
    "\n",
    "'''img = cv2.imread(os.path.join('finaltrain/train',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imgr = np.array([img])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec = FECNN.predict(imgr)'''\n",
    "    \n",
    "detector = MTCNN()\n",
    "\n",
    "for filename in os.listdir('SRtrain/train'):\n",
    "    pixels = cv2.imread(os.path.join('SRtrain/train',filename))\n",
    "    pixels = cv2.cvtColor(pixels, cv2.COLOR_BGR2RGB)\n",
    "    #results = detector.detect_faces(pixels)\n",
    "    #x1, y1, width, height = results[0]['box']\n",
    "    #x1, y1 = abs(x1), abs(y1)\n",
    "    #x2, y2 = x1 + width, y1 + height\n",
    "    #img = pixels[y1:y2, x1:x2]\n",
    "    #img = cv2.resize(img, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "    img = pixels.astype('float32')\n",
    "    mean, std = img.mean(), img.std()\n",
    "    img = (img - mean) / std\n",
    "    imgr = np.array([img])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec = model1.predict(imgr)\n",
    "    #vec = vec/np.linalg.norm(vec)\n",
    "    #print(vec)\n",
    "    x.append(vec.flatten())\n",
    "    #vec1 = vec1/np.linalg.norm(vec1)\n",
    "    #a = []\n",
    "    '''for j in range(50):\n",
    "        k = 's' + str(j)\n",
    "        vec2 = dic[k]/np.linalg.norm(dic[k])\n",
    "        dist = tf.reduce_sum(K.sqrt(K.square(vec2-vec1)))\n",
    "        a.append(dist)'''  \n",
    "#print(x)\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "#plt.ylim([-30,30])\n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('FECNN Features PCA', fontsize = 20)\n",
    "colors = ['r', 'g', 'b','c','m','y','k','gold','grey','purple']\n",
    "k=[0,2,6,8,9]\n",
    "for i in range(10):\n",
    "    ax.scatter(principalDf.loc[range((i*10),((i*10)+10)), 'principal component 1']\n",
    "               , principalDf.loc[range((i*10),((i*10)+10)), 'principal component 2']\n",
    "               , c = colors[i]\n",
    "               , s = 50)\n",
    "#ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "#plt.ylim([-30,30])\n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('FECNN Features PCA', fontsize = 20)\n",
    "colors = ['r', 'g', 'b','c','m','y','k','gold','grey','purple']\n",
    "k=[0,2,6,8,9]\n",
    "for i in range(10):\n",
    "    ax.scatter(principalDf.loc[range((i*10),((i*10)+10)), 'principal component 1']\n",
    "               , principalDf.loc[range((i*10),((i*10)+10)), 'principal component 2']\n",
    "               , c = colors[i]\n",
    "               , s = 50)\n",
    "#ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict()\n",
    "i=0\n",
    "accuracy = 0\n",
    "threshold = 2.2\n",
    "for filename in os.listdir('finaltrain/train'):\n",
    "    img = cv2.imread(os.path.join('finaltrain/train',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imgr = np.array([img])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec = FECNN.predict(imgr)\n",
    "    dic['s'+ str(i)] = vec\n",
    "    i = i+1\n",
    "i=0\n",
    "dic1 = dict()\n",
    "for filename in os.listdir('finaltest/test'):\n",
    "    img = cv2.imread(os.path.join('finaltest/test',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img1 = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    imgr = np.array([img1])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec1 = SRFECNN.predict(imgr)\n",
    "    vec1 = vec1/np.linalg.norm(vec1)\n",
    "    temp = 9999999\n",
    "    for j in range(500):\n",
    "        k = 's' + str(j)\n",
    "        vec2 = dic[k]/np.linalg.norm(dic[k])\n",
    "        dist = tf.reduce_sum(K.sqrt(K.square(vec2-vec1)))\n",
    "        if(dist.numpy()<temp):\n",
    "            temp = dist.numpy()\n",
    "            dic1[i].append(j)\n",
    "            dic1[i].append(temp)\n",
    "    i = i+1\n",
    "for test, subject, distance in dic1.items():\n",
    "    if(int(test/5)==int(subject/10) and distance<threshold):\n",
    "        accuracy = accuracy + 1\n",
    "                    \n",
    "print((accuracy/250)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [0.] + history.history['accuracy']\n",
    "val_acc = [0.] + history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.ylim([0,100])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('train/train/ATT_49_1988739.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#display(array_to_img(img))\n",
    "#print(img)\n",
    "#plt.imshow(img)\n",
    "img = img/255\n",
    "img1 = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "img1 = cv2.resize(img, (36,36), interpolation=cv2.INTER_CUBIC)\n",
    "img1 = cv2.resize(img1, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "#img1 = img1*255\n",
    "plt.imshow(img1)\n",
    "\n",
    "#cv2.imwrite('HR1.bmp', img1)\n",
    "#original = cv2.imread(\"HR1.bmp\")\n",
    "#print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgr = np.array([img1])\n",
    "imgr = tf.convert_to_tensor(imgr)\n",
    "img_HR = model.predict(imgr)\n",
    "#print(img_HR)\n",
    "img2 = np.array(img_HR,dtype=np.uint8)\n",
    "img2 = img2[0,:]\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict()\n",
    "i=0\n",
    "for filename in os.listdir('finaltrain/finaltrain'):\n",
    "    img = cv2.imread(os.path.join('finaltrain/finaltrain',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    imgr = np.array([img])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec = FECNN.predict(imgr)\n",
    "    dic['s'+ str(i)] = vec\n",
    "    i = i+1\n",
    "i=0\n",
    "Dist_pred=[]\n",
    "ID_pred=dict()\n",
    "io_labels_pred = [] #in  - 1, out - 0.\n",
    "io_labels_orig = [0 for i in range(40)] + [1 for i in range(40,70)]\n",
    "ID_orig = [-1 for i in range(40)] + [int(i/3) for i in range(30)]\n",
    "names = dict(zip([0,1,2,3,4,5,6,7,8,9],['Arsalan','Tony','Peter','Steve','Bucky','Wanda','Harry','Ron','Loki','Hrishi']))\n",
    "names_pred = []\n",
    "\n",
    "io_acc = 0\n",
    "ID_acc = 0\n",
    "threshold = 0.235\n",
    "files = []\n",
    "idx = []\n",
    "i=0\n",
    "for filename in os.listdir('finaltest/test'):\n",
    "    files.append(os.path.join('finaltest/test',filename))\n",
    "    img = cv2.imread(os.path.join('finaltest/test',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    img1 = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    imgr = np.array([img1])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec1 = SRFECNN.predict(imgr)\n",
    "    vec1 = vec1/np.linalg.norm(vec1)\n",
    "    a = []\n",
    "    for j in range(100):\n",
    "        k = 's' + str(j)\n",
    "        vec2 = dic[k]/np.linalg.norm(dic[k])\n",
    "        dist = np.linalg.norm(vec2-vec1)\n",
    "        dist = dist.flatten()\n",
    "        a.append(dist[0])\n",
    "    Dist_pred.append(min(a))\n",
    "    ID_pred[i]=int(np.argmin(a)/10)\n",
    "    #print(np.argmin(a))\n",
    "    i+=1\n",
    "\n",
    "for i in Dist_pred:\n",
    "    if i<=threshold:\n",
    "        io_labels_pred.append(1)\n",
    "    else:\n",
    "        io_labels_pred.append(0)\n",
    "\n",
    "for i in range(len(io_labels_pred)):\n",
    "    if io_labels_pred[i] == io_labels_orig[i]:\n",
    "        io_acc += 1\n",
    "    if io_labels_pred[i]==1:\n",
    "        if ID_pred[i] == ID_orig[i]:\n",
    "            ID_acc += 1\n",
    "            names_pred.append(names[ID_pred[i]])\n",
    "\n",
    "    \n",
    "'''print(\"Dist_pred: \",Dist_pred)\n",
    "print(\"ID_pred: \",ID_pred)\n",
    "print(\"io_labels_pred: \",io_labels_pred)\n",
    "print(\"io_labels_orig: \",io_labels_orig)\n",
    "print(\"ID_orig: \",ID_orig)\n",
    "print(\"names: \",names)\n",
    "print(\"names_pred: \",names_pred)\n",
    "print(\"io_acc = \",io_acc,\"ID_acc = \",ID_acc)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=7,\n",
    "                              verbose=0, mode='min', restore_best_weights=False)'''\n",
    "\n",
    "input_img = Input(shape=(224,224,3))\n",
    "C1 = Conv2D(96,(9,9),padding='SAME',name='CONV1')(input_img)\n",
    "A1 = Activation('relu', name='act1')(C1)\n",
    "C2 = Conv2D(64,(1,1),padding='SAME',name='CONV2')(A1)\n",
    "A2 = Activation('relu', name='act2')(C2)\n",
    "C3 = Conv2D(48,(1,1),padding='SAME',name='CONV3')(A2)\n",
    "A3 = Activation('relu', name='act3')(C3)\n",
    "C4 = Conv2D(32,(1,1),padding='SAME',name='CONV4')(A3)\n",
    "A4 = Activation('relu', name='act4')(C4)\n",
    "C5 = Conv2D(3,(5,5),padding='SAME',name='CONV5')(A4)\n",
    "A5 = Activation('relu', name='act5')(C5)\n",
    "S = Model(input_img, A5)\n",
    "\n",
    "\n",
    "S.load_weights('Models/SR/epoch101-110/SRnetweights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgt = cv2.imread('finaltest/test/GEO_27_3031237.jpg')\n",
    "imgt = cv2.cvtColor(imgt, cv2.COLOR_BGR2RGB)\n",
    "imgt=imgt/255\n",
    "def LR(image):\n",
    "    image = cv2.resize(image, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    image = cv2.resize(image, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    return image\n",
    "imgT1 = LR(imgt)\n",
    "imgr1 = np.array([imgT1])\n",
    "imgr1 = tf.convert_to_tensor(imgr1)\n",
    "img_fecnn = FECNN.predict(imgr1)\n",
    "img_fecnn = np.array(img_fecnn,dtype=np.uint8)\n",
    "img_fecnn = img_fecnn[0]\n",
    "img_fecnn = img_fecnn/np.linalg.norm(img_fecnn)\n",
    "img_fecnn = img_fecnn.reshape((64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgt1 = cv2.imread('finaltest/test/GEO_27_3031237.jpg')\n",
    "imgt1 = cv2.cvtColor(imgt1, cv2.COLOR_BGR2RGB)\n",
    "imghr = cv2.resize(imgt1, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "imgt1=imgt1/255\n",
    "def LR(image):\n",
    "    image = cv2.resize(image, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    image = cv2.resize(image, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    return image\n",
    "imgT1 = LR(imgt1)\n",
    "imgr1 = np.array([imgT1])\n",
    "imgr1 = tf.convert_to_tensor(imgr1)\n",
    "img_SR1 = S.predict(imgr1)\n",
    "img_vec1 = SRFECNN.predict(imgr1)\n",
    "#img_fecnn = FECNN.predict(imgr1)\n",
    "imgSR1 = np.array(img_SR1,dtype=np.uint8)\n",
    "imgSR1 = imgSR1[0,:]\n",
    "img_vec1 = np.array(img_vec1,dtype=np.uint8)\n",
    "img_vec1 = img_vec1[0]\n",
    "img_vec1 = img_vec1/np.linalg.norm(img_vec1)\n",
    "img_vec1 = img_vec1.reshape((64,64))\n",
    "\n",
    "fig = plt.figure(figsize = (12,12), dpi = 100)\n",
    "\n",
    "ax = plt.subplot(1,4,1)\n",
    "ax.imshow(imghr)\n",
    "ax.set_title(\"Original Image\")\n",
    "plt.grid(0)\n",
    "\n",
    "ax = plt.subplot(1,4,2)\n",
    "ax.imshow(imgT1)\n",
    "ax.set_title(\"LR Image\")\n",
    "plt.grid(0)\n",
    "\n",
    "ax = plt.subplot(1,4,3)\n",
    "ax.imshow(img_fecnn,cmap='Greys')\n",
    "ax.set_title(\"FECNN Output\")\n",
    "plt.grid(0)\n",
    "\n",
    "ax = plt.subplot(1,4,4)\n",
    "ax.imshow(img_vec1,cmap='Greys')\n",
    "ax.set_title(\"SRFECNN Output\")\n",
    "plt.grid(0)\n",
    "print(\"True Label: Peter, Predicted Label: Peter\")\n",
    "print(\"Database True Label: 1, Predicted Label: 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
