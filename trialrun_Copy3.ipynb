{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zrq1dpKydnqy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation, Input #changed 'keras.' to 'tensorflow.keras.'\n",
    "from tensorflow.keras.models import Sequential, Model #changed 'keras.' to 'tensorflow.keras.'\n",
    "from tensorflow.keras import optimizers #changed 'keras.' to 'tensorflow.keras.'\n",
    "import cv2\n",
    "import math\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import Sequential\n",
    "from IPython.display import display\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7th93J3xdnq3",
    "outputId": "24c32847-8d0e-448c-c86a-dbf00014e307"
   },
   "outputs": [],
   "source": [
    "model = VGGFace()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vggface_vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc6/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "fc7/relu (Activation)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 2622)              10742334  \n",
      "_________________________________________________________________\n",
      "fc8/softmax (Activation)     (None, 2622)              0         \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Nj9K6VjFdnq6",
    "outputId": "cf918666-0d88-4bcb-f3ca-01ad27e980b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc6/relu (Activation)        (None, 4096)              0         \n",
      "=================================================================\n",
      "Total params: 117,479,232\n",
      "Trainable params: 115,743,744\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "temp = Sequential()\n",
    "for layer in model.layers[0:-4]: # just exclude last two layers from copying\n",
    "    temp.add(layer)\n",
    "\n",
    "for layer in temp.layers[0:9]:\n",
    "    layer.trainable = False\n",
    "temp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.save_weights('tempweights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGD-GXySdnq8",
    "outputId": "8592e4b3-08c1-4870-c2a5-1f7dc5114765"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "directory = \"newtrain\"\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory, label_mode=None, color_mode='rgb', batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=True, seed=0, validation_split=None, subset=None,\n",
    "    interpolation='bicubic', follow_links=False)\n",
    "directory = \"newval\"\n",
    "valid_ds = image_dataset_from_directory(\n",
    "    directory, label_mode=None, color_mode='rgb', batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=True, seed=0, validation_split=None, subset=None,\n",
    "    interpolation='bicubic', follow_links=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f5C4Ry59dnq9"
   },
   "outputs": [],
   "source": [
    "SR = keras.models.load_model('Models/SR/SRnet')\n",
    "SR.load_weights('Models/SR/epoch101-110/SRnetweights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "diXmAcgldnq-",
    "outputId": "c6dea251-c0c4-40ed-8d35-42fdae2e6e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 224, 224, 3)       36723     \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 4096)              117479232 \n",
      "=================================================================\n",
      "Total params: 117,515,955\n",
      "Trainable params: 115,743,744\n",
      "Non-trainable params: 1,772,211\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=7,\n",
    "                              verbose=0, mode='min', restore_best_weights=False)'''\n",
    "\n",
    "input_img = Input(shape=(224,224,3))\n",
    "A5 = SR(input_img) \n",
    "A6 = temp(A5)\n",
    "SRFECNN = Model(input_img, A6)\n",
    "opt = optimizers.Adam(learning_rate = 0.000003)\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "SRFECNN.compile(\n",
    "    optimizer=opt,\n",
    "    loss=root_mean_squared_error,\n",
    "    metrics=['accuracy'])\n",
    "for layer in SRFECNN.layers[0:-1]:\n",
    "    layer.trainable = False\n",
    "#SRFECNN.load_weights('Models/twobranch/twobranch_weights_e1_rms.h5')\n",
    "#SRFECNN.compile(optimizer=opt,loss='root_mean_squared_error',metrics=['accuracy'])\n",
    "SRFECNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6496/4242365368.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSRFECNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Models/twobranch_overfit/5unfreezed_epoch30.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSRFECNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# just exclude last two layers from copying\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2324\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0;32m   2325\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2326\u001b[1;33m         \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2328\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[0msymbolic_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_legacy_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m     weight_values = preprocess_weights_for_loading(\n\u001b[0m\u001b[0;32m    703\u001b[0m         layer, weight_values, original_keras_version, original_backend)\n\u001b[0;32m    704\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[1;34m(layer, weights, original_keras_version, original_backend)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sequential'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[1;34m(weights)\u001b[0m\n\u001b[0;32m    301\u001b[0m       \u001b[0mnum_non_trainable_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnon_trainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0msublayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         preprocessed = preprocess_weights_for_loading(\n\u001b[0m\u001b[0;32m    304\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             weights=(trainable_weights[:num_trainable_weights] +\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[1;34m(layer, weights, original_keras_version, original_backend)\u001b[0m\n\u001b[0;32m    402\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconv_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m       \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ConvLSTM2D'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \"\"\"\n\u001b[1;32m--> 660\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'transpose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VA_yokSkdnq_"
   },
   "outputs": [],
   "source": [
    "FECNN = Sequential()\n",
    "for layer in model.layers[0:-4]: # just exclude last two layers from copying\n",
    "    FECNN.add(layer)\n",
    "for layer in FECNN.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "#FECNN.save('Models/FECNN')\n",
    "#SRFECNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4Yj2y8dNdnrA"
   },
   "outputs": [],
   "source": [
    "# to generate training images, we first need to downscale the image by scaler factor and then upscale it back to the original size\n",
    "def create_LR(image): \n",
    "    image = image / 255 #normalising the pixel values\n",
    "    image = tf.image.resize(image, [24, 24], method=\"bicubic\") #for 36x35, batches~75, loss~4000, accuracy~62\n",
    "    image = tf.image.resize(image, [224, 224], method=\"bicubic\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1taXGGQLdnrB",
    "outputId": "a2a3f5c5-3f4e-40a2-b105-bebe58fac2f9"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.map(\n",
    "    lambda x: (create_LR(x), FECNN(x))\n",
    ")\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(\n",
    "    lambda x: (create_LR(x), FECNN(x))\n",
    ")\n",
    "valid_ds = valid_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tZ0AF5C7dnrC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 4096)              117479232 \n",
      "=================================================================\n",
      "Total params: 117,479,232\n",
      "Trainable params: 0\n",
      "Non-trainable params: 117,479,232\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SRFECNN.load_weights('Models/twobranch_overfit/5unfreezed_epoch30.h5')\n",
    "#SRFECNN.load_weights('Models/twobranch_overfit/5unfreezed_epoch30.h5')\n",
    "\n",
    "input_img = Input(shape=(224,224,3))\n",
    "A5 = SRFECNN.layers[2](input_img) \n",
    "#A6 = SRFECNN.layers[2](A5)\n",
    "net = Model(input_img, A5)\n",
    "#net.add(keras.Input(shape=(224,224,3)))\n",
    "#for layer in SRFECNN.layers[2:]: # just exclude last two layers from copying\n",
    "    #net.add(layer)\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQdwZ2nGdnrC"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "history = SRFECNN.fit(train_ds, epochs=1, validation_data=valid_ds)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVwh59srdnrD"
   },
   "outputs": [],
   "source": [
    "#SRFECNN.save('Models/SRFECNN')\n",
    "#SRFECNN.save('Models/twobranch/twobranch_weights_e1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juY6v9ckdnrD"
   },
   "outputs": [],
   "source": [
    "SRFECNN.save('Models/twobranch/twobranch_weights_e1_rms.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "LIYDxDWwdnrE",
    "outputId": "941cf4c1-0901-4b04-d8d7-3bc9b6b9f069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  0.  7. ...  0.  0.  0.]\n",
      " [ 5.  0.  0. ...  0.  0.  0.]\n",
      " [ 5. 10.  8. ... 10. 10. 10.]\n",
      " ...\n",
      " [ 5. 10. 10. ... 10. 10. 10.]\n",
      " [ 5. 10. 10. ... 10. 10. 10.]\n",
      " [ 5. 10.  3. ...  8.  8. 10.]]\n",
      "[ 2  0  1  2  1  1  1  1  0  1  1  1  1  3  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  0  1  1  1  1  1  3  1  1  1  1 33  1  1  1  1  0  1  1  1  1\n",
      "  1  1]\n",
      "0\n",
      "0.0013310327828444663\n",
      "54.0\n"
     ]
    }
   ],
   "source": [
    "dic = dict()\n",
    "i=0\n",
    "TP = 0\n",
    "for filename in os.listdir('SRtrain/train'):\n",
    "    img = cv2.imread(os.path.join('SRtrain/train',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    imgr = np.array([img])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec = FECNN.predict(imgr)\n",
    "    dic['s'+ str(i)] = vec\n",
    "    i = i+1\n",
    "i=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0\n",
    "accuracy = 0\n",
    "acc = 0\n",
    "a = np.zeros((50,50))\n",
    "threshold = 0.235\n",
    "for filename in os.listdir('finaltest/test'):\n",
    "    img = cv2.imread(os.path.join('finaltest/test',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    img1 = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    imgr = np.array([img1])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec1 = SRFECNN.predict(imgr)\n",
    "    vec1 = vec1/np.linalg.norm(vec1)\n",
    "    a = []\n",
    "    for j in range(100):\n",
    "        k = 's' + str(j)\n",
    "        vec2 = dic[k]/np.linalg.norm(dic[k])\n",
    "        dist = np.linalg.norm(vec2-vec1)\n",
    "        dist = dist.flatten()\n",
    "        a.append(dist)\n",
    "    Dist_pred.append(min(a))\n",
    "    ID_pred.append(np.argmin(a))\n",
    "for i in Dist_pred:\n",
    "    \n",
    "        if dist.numpy()<=5:\n",
    "            a[i,int(j/10)] += 1\n",
    "\n",
    "        if dist.numpy()<=5 and j==int(i/5):\n",
    "            TP = TP + 1\n",
    "            accuracy = accuracy + 1\n",
    "        elif dist.numpy()<=5 and j!=int(i/5): \n",
    "            FP = FP + 1\n",
    "        \n",
    "        #print(\"dist = \",dist,\"subject = \",j,\"i = \",i)\n",
    "    i = i+1\n",
    "\n",
    "b = np.argmax(a, axis=1)\n",
    "for i in range(50):\n",
    "    if i==b[i]:\n",
    "        acc += 1\n",
    "print(a)\n",
    "print(b)\n",
    "print(acc*2)\n",
    "P = TP/(TP+FP)\n",
    "R = TP/(TP+FN)\n",
    "F1 = 2*P*R/(P+R)\n",
    "print(P)\n",
    "print((accuracy/50)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7L9sRl_dnrF",
    "outputId": "e2d221f5-9fc4-4b0a-95f0-f8559699039b"
   },
   "outputs": [],
   "source": [
    "dic = dict()\n",
    "i=0\n",
    "accuracy = 0\n",
    "threshold = 2.2\n",
    "for filename in os.listdir('finaltrain/train'):\n",
    "    img = cv2.imread(os.path.join('finaltrain/train',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imgr = np.array([img])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec = FECNN.predict(imgr)\n",
    "    dic['s'+ str(i)] = vec\n",
    "    i = i+1\n",
    "i=0\n",
    "dic1 = dict()\n",
    "for filename in os.listdir('finaltest/test'):\n",
    "    img = cv2.imread(os.path.join('finaltest/test',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img1 = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    imgr = np.array([img1])\n",
    "    imgr = tf.convert_to_tensor(imgr)\n",
    "    vec1 = SRFECNN.predict(imgr)\n",
    "    vec1 = vec1/np.linalg.norm(vec1)\n",
    "    temp = 9999999\n",
    "    for j in range(500):\n",
    "        k = 's' + str(j)\n",
    "        vec2 = dic[k]/np.linalg.norm(dic[k])\n",
    "        dist = tf.reduce_sum(K.sqrt(K.square(vec2-vec1)))\n",
    "        if(dist.numpy()<temp):\n",
    "            temp = dist.numpy()\n",
    "            dic1[i].append(j)\n",
    "            dic1[i].append(temp)\n",
    "    i = i+1\n",
    "for test, subject, distance in dic1.items():\n",
    "    if(int(test/5)==int(subject/10) and distance<threshold):\n",
    "        accuracy = accuracy + 1\n",
    "                    \n",
    "print((accuracy/250)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5LzCQrsdnrG"
   },
   "outputs": [],
   "source": [
    "acc = [0.] + history.history['accuracy']\n",
    "val_acc = [0.] + history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.ylim([0,100])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1fE88wbdnrG"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('train/train/ATT_49_1988739.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#display(array_to_img(img))\n",
    "#print(img)\n",
    "#plt.imshow(img)\n",
    "img = img/255\n",
    "img1 = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "img1 = cv2.resize(img, (36,36), interpolation=cv2.INTER_CUBIC)\n",
    "img1 = cv2.resize(img1, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "#img1 = img1*255\n",
    "plt.imshow(img1)\n",
    "\n",
    "#cv2.imwrite('HR1.bmp', img1)\n",
    "#original = cv2.imread(\"HR1.bmp\")\n",
    "#print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEHKaE_3dnrH"
   },
   "outputs": [],
   "source": [
    "imgr = np.array([img1])\n",
    "imgr = tf.convert_to_tensor(imgr)\n",
    "img_HR = model.predict(imgr)\n",
    "#print(img_HR)\n",
    "img2 = np.array(img_HR,dtype=np.uint8)\n",
    "img2 = img2[0,:]\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LSffjLCdnrH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "trialrun-Copy2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
