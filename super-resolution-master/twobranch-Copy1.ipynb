{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data import DIV2K\n",
    "from model.edsr import edsr\n",
    "from train import EdsrTrainer\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation, Input #changed 'keras.' to 'tensorflow.keras.'\n",
    "from tensorflow.keras.models import Sequential, Model #changed 'keras.' to 'tensorflow.keras.'\n",
    "from tensorflow.keras import optimizers #changed 'keras.' to 'tensorflow.keras.'\n",
    "import cv2\n",
    "import math\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from IPython.display import display\n",
    "import sys\n",
    "from keras.models import load_model\n",
    "import mtcnn\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.applications import resnet\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "target_shape = (160, 160)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from data import DIV2K\n",
    "from model.wdsr import wdsr_b\n",
    "from model.srgan import generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mtcnn\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import matplotlib.pyplot as plt\n",
    "detector = MTCNN()\n",
    "\n",
    "def process(pixels):\n",
    "    results = detector.detect_faces(pixels)\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    img = pixels[y1:y2, x1:x2]\n",
    "    return img\n",
    "\n",
    "img = cv2.imread('WhatsApp Image 2021-08-31 at 11.29.34 AM.jpeg')\n",
    "img1 = cv2.resize(img, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "img1 = cv2.resize(img1, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imwrite('mtcnn.jpg',img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    SRCNN = Sequential()  \n",
    "\n",
    "    _# add model layers_  \n",
    "    SRCNN.add(Conv2D(filters=128, kernel_size = (9, 9), kernel_initializer='glorot_uniform',  \n",
    "                     activation='relu', padding='valid', use_bias=True, input_shape=(160, 160, 1)))  \n",
    "    SRCNN.add(Conv2D(filters=64, kernel_size = (3, 3), kernel_initializer='glorot_uniform',  \n",
    "                     activation='relu', padding='same', use_bias=True))  \n",
    "    SRCNN.add(Conv2D(filters=1, kernel_size = (5, 5), kernel_initializer='glorot_uniform',  \n",
    "                     activation='linear', padding='valid', use_bias=True))  \n",
    "\n",
    "    _# define optimizer_  \n",
    "    adam = optimizers.Adam(lr=0.0003)  \n",
    "\n",
    "    _# compile model_  \n",
    "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error']) \n",
    "    return SRCNN\n",
    "srcnn = model()\n",
    "srcnn.load_weights('3051crop_weight_200.h5')\n",
    "srcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('0000.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 32\n",
    "scale = 4\n",
    "downgrade = 'bicubic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_generator = generator()\n",
    "gan_generator = generator()\n",
    "\n",
    "pre_generator.load_weights('weights/srgan/pre_generator.h5')\n",
    "gan_generator.load_weights('weights/srgan/gan_generator.h5')\n",
    "for layer in pre_generator.layers:\n",
    "    layer.trainable = False\n",
    "for layer in gan_generator.layers:\n",
    "    layer.trainable = False\n",
    "#print(pre_generator.summary())\n",
    "#print(gan_generator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = wdsr_b(scale=scale, num_res_blocks=32)\n",
    "SR.load_weights('weights/wdsr-b-32-x4/weights.h5')\n",
    "for layer in SR.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import resolve_single\n",
    "from utils import load_image, plot_sample\n",
    "\n",
    "def resolve(model, lr_batch):\n",
    "    lr_batch = tf.cast(lr_batch, tf.float32)\n",
    "    sr_batch = model(lr_batch)\n",
    "    sr_batch = tf.clip_by_value(sr_batch, 0, 255)\n",
    "    sr_batch = tf.round(sr_batch)\n",
    "    sr_batch = tf.cast(sr_batch, tf.uint8)\n",
    "    return sr_batch\n",
    "\n",
    "def resolve_and_plot(lr):\n",
    "    lr = tf.image.resize(lr, [24,24], method = 'bicubic')\n",
    "    sr = resolve(pre_generator, lr)\n",
    "    sr = resolve(gan_generator, sr)\n",
    "    sr = tf.image.resize(sr, [160,160], method = 'bicubic')\n",
    "    image = tf.image.convert_image_dtype(sr, tf.float32)\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsal\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1059: UserWarning: inception_resnet_v1 is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  warnings.warn('{} is not loaded, but a Lambda layer uses it. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "FECNN = keras.models.load_model('../keras-facenet-master/keras-facenet-master/model/keras/model/facenet_keras.h5')\n",
    "FECNN.load_weights('../keras-facenet-master/keras-facenet-master/model/keras/weights/facenet_keras_weights.h5')\n",
    "for layer in FECNN.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsal\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1059: UserWarning: inception_resnet_v1 is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  warnings.warn('{} is not loaded, but a Lambda layer uses it. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"inception_resnet_v1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 17, 17, 256)  0           Block35_1_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Activation (Activatio (None, 17, 17, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 17, 17, 256)  0           Block35_2_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Activation (Activatio (None, 17, 17, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 17, 17, 256)  0           Block35_3_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Activation (Activatio (None, 17, 17, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 17, 17, 256)  0           Block35_4_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Activation (Activatio (None, 17, 17, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 17, 17, 256)  0           Block35_5_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Activation (Activatio (None, 17, 17, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 8, 8, 896)    0           Block17_1_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Activation (Activatio (None, 8, 8, 896)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 8, 8, 896)    0           Block17_2_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Activation (Activatio (None, 8, 8, 896)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_3_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_3_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_3_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_3_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_3_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 8, 8, 896)    0           Block17_3_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 896)    0           Block17_2_Activation[0][0]       \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Activation (Activatio (None, 8, 8, 896)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_4_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_4_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_4_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_4_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_4_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 8, 8, 896)    0           Block17_4_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 896)    0           Block17_3_Activation[0][0]       \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Activation (Activatio (None, 8, 8, 896)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_5_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_5_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_5_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_5_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_5_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 8, 8, 896)    0           Block17_5_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 896)    0           Block17_4_Activation[0][0]       \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Activation (Activatio (None, 8, 8, 896)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_6_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_6_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_6_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_6_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_6_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 8, 8, 896)    0           Block17_6_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 896)    0           Block17_5_Activation[0][0]       \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Activation (Activatio (None, 8, 8, 896)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_7_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_7_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_7_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_7_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_7_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 8, 8, 896)    0           Block17_7_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 896)    0           Block17_6_Activation[0][0]       \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Activation (Activatio (None, 8, 8, 896)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_8_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_8_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_8_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_8_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_8_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 8, 8, 896)    0           Block17_8_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 896)    0           Block17_7_Activation[0][0]       \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Activation (Activatio (None, 8, 8, 896)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_9_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_9_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_9_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_9_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_9_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 8, 8, 896)    0           Block17_9_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 896)    0           Block17_8_Activation[0][0]       \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Activation (Activatio (None, 8, 8, 896)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    384         Block17_10_Branch_0_Conv2d_1x1[0]\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    0           Block17_10_Branch_0_Conv2d_1x1_Ba\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Concatenate (Concate (None, 8, 8, 256)    0           Block17_10_Branch_0_Conv2d_1x1_Ac\n",
      "                                                                 Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      Block17_10_Concatenate[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 8, 8, 896)    0           Block17_10_Conv2d_1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 896)    0           Block17_9_Activation[0][0]       \n",
      "                                                                 lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Activation (Activati (None, 8, 8, 896)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    589824      Mixed_7a_Branch_2_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_0_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0b_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_0_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0b_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    884736      Mixed_7a_Branch_0_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_2_Conv2d_0b_3x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    1152        Mixed_7a_Branch_0_Conv2d_1a_3x3[0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_1_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_2_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    0           Mixed_7a_Branch_0_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_1_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_2_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_3_MaxPool_1a_3x (None, 3, 3, 896)    0           Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a (Concatenate)          (None, 3, 3, 1792)   0           Mixed_7a_Branch_0_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_1_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_2_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_3_MaxPool_1a_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_1_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_1_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_1_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_1_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_1_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 3, 3, 1792)   0           Block8_1_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 3, 3, 1792)   0           Mixed_7a[0][0]                   \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Activation (Activation (None, 3, 3, 1792)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_2_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_2_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_2_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_2_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_2_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 3, 3, 1792)   0           Block8_2_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 3, 3, 1792)   0           Block8_1_Activation[0][0]        \n",
      "                                                                 lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Activation (Activation (None, 3, 3, 1792)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_3_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_3_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_3_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_3_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_3_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 3, 3, 1792)   0           Block8_3_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 3, 3, 1792)   0           Block8_2_Activation[0][0]        \n",
      "                                                                 lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Activation (Activation (None, 3, 3, 1792)   0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_4_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_4_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_4_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_4_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_4_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 3, 3, 1792)   0           Block8_4_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 3, 3, 1792)   0           Block8_3_Activation[0][0]        \n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Activation (Activation (None, 3, 3, 1792)   0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_5_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_5_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_5_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_5_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_5_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 3, 3, 1792)   0           Block8_5_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 3, 3, 1792)   0           Block8_4_Activation[0][0]        \n",
      "                                                                 lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Activation (Activation (None, 3, 3, 1792)   0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_6_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_6_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_6_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_6_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_6_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 3, 3, 1792)   0           Block8_6_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 3, 3, 1792)   0           Block8_5_Activation[0][0]        \n",
      "                                                                 lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (GlobalAveragePooling2D (None, 1792)         0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Dropout (Dropout)               (None, 1792)         0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck (Dense)              (None, 512)          917504      Dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_BatchNorm (BatchNorm (None, 512)          1536        Bottleneck[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,497,424\n",
      "Trainable params: 23,467,824\n",
      "Non-trainable params: 29,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "temp = keras.models.load_model('../keras-facenet-master/keras-facenet-master/model/keras/model/facenet_keras.h5')\n",
    "temp.load_weights('../keras-facenet-master/keras-facenet-master/model/keras/weights/facenet_keras_weights.h5')\n",
    "temp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = (160,160)\n",
    "\n",
    "directory = \"../low-res-face-recognition/Dataset/final_gen_data_10/train\"\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory, label_mode=None, color_mode='rgb', batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=True, seed=0, validation_split=None, subset=None,\n",
    "    interpolation='bicubic', follow_links=False)\n",
    "directory = \"../low-res-face-recognition/Dataset/final_gen_data_10/val\"\n",
    "valid_ds = image_dataset_from_directory(\n",
    "    directory, label_mode=None, color_mode='rgb', batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=True, seed=0, validation_split=None, subset=None,\n",
    "    interpolation='bicubic', follow_links=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(x):\n",
    "    image = tf.image.convert_image_dtype(x, tf.float32)\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    image = FECNN(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.map(\n",
    "    lambda x: (resolve_and_plot(x), hr(x))\n",
    ")\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(\n",
    "    lambda x: (resolve_and_plot(x), hr(x))\n",
    ")\n",
    "valid_ds = valid_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v1 (Functio (None, 512)               23497424  \n",
      "=================================================================\n",
      "Total params: 23,497,424\n",
      "Trainable params: 23,467,824\n",
      "Non-trainable params: 29,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(160,160,3))\n",
    "A6 = temp(input_img)\n",
    "SRFECNN = Model(input_img, A6)\n",
    "opt = optimizers.Adam()\n",
    "    \n",
    "SRFECNN.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "SRFECNN.summary()\n",
    "SRFECNN.load_weights('../twobranch_extension/209_subjects/24,24_bicubic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = ModelCheckpoint(filepath='../twobranch_extension/10_subjects_16,16_bicubic.h5',\n",
    "                                            save_weights_only = True,\n",
    "                                            period = 1,\n",
    "                                            verbose = 1,\n",
    "                                            save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc_arr = []\n",
    "val_acc_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ite in range(45):\n",
    "    if ite == 30:\n",
    "        opt = optimizers.Adam(learning_rate = 0.0001)\n",
    "        SRFECNN.compile(\n",
    "            optimizer=opt,\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    if ite == 40:\n",
    "        opt = optimizers.Adam(learning_rate = 0.00001)\n",
    "        SRFECNN.compile(\n",
    "            optimizer=opt,\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    if ite > 0:\n",
    "        SRFECNN.load_weights('../twobranch_extension/10_subjects_16,16_bicubic.h5')\n",
    "        \n",
    "    history = SRFECNN.fit(train_ds, epochs=1, validation_data=valid_ds, callbacks = [model_checkpoint_callback])\n",
    "'''    \n",
    "    train_loss.append(history.history['loss'][0])\n",
    "    val_loss.append(history.history['val_loss'][0])\n",
    "\n",
    "    i=0\n",
    "    j=1\n",
    "    temp = []\n",
    "    data = np.zeros((2090,512))\n",
    "    train_labels = np.zeros((2090,))\n",
    "    for filename in os.listdir('../low-res-face-recognition/Dataset/final_gen_data_209/train'):\n",
    "        lr = cv2.imread(os.path.join('../low-res-face-recognition/Dataset/final_gen_data_209/train',filename))\n",
    "        lr = cv2.cvtColor(lr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        lr = cv2.resize(lr, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "        lr = resolve_single(pre_generator, lr)\n",
    "        lr = resolve_single(gan_generator, lr)\n",
    "        lr = np.array(lr)\n",
    "        lr = cv2.resize(lr, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        lr = lr.astype('float32')\n",
    "        mean, std = lr.mean(), lr.std()\n",
    "        lr = (lr - mean) / std\n",
    "\n",
    "        lr = np.array([lr])\n",
    "        lr = tf.convert_to_tensor(lr)\n",
    "        vec1 = SRFECNN.predict(lr)\n",
    "        vec1 = vec1.flatten() \n",
    "        data[i] = vec1\n",
    "        train_labels[i] = int(i/10)\n",
    "        i += 1\n",
    "    \n",
    "    #STANDARDIZATION\n",
    "\n",
    "    mean_arr = []\n",
    "    std_arr = []\n",
    "    for i in range(len(data[0])):\n",
    "        x = data[:,i]\n",
    "        x = x.astype('float32')\n",
    "        mean, std = x.mean(), x.std()\n",
    "        x = (x - mean) / std\n",
    "        mean_arr.append(mean)\n",
    "        std_arr.append(std)\n",
    "        data[:,i] = x\n",
    "        \n",
    "    i=0\n",
    "    j=1\n",
    "    temp = []\n",
    "    val = np.zeros((418,512))\n",
    "    val_labels = np.zeros((418,))\n",
    "    for filename in os.listdir('../low-res-face-recognition/Dataset/final_gen_data_209/val'):\n",
    "        lr = cv2.imread(os.path.join('../low-res-face-recognition/Dataset/final_gen_data_209/val',filename))\n",
    "        lr = cv2.cvtColor(lr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        lr = cv2.resize(lr, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "        lr = resolve_single(pre_generator, lr)\n",
    "        lr = resolve_single(gan_generator, lr)\n",
    "        lr = np.array(lr)\n",
    "        lr = cv2.resize(lr, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        lr = lr.astype('float32')\n",
    "        mean, std = lr.mean(), lr.std()\n",
    "        lr = (lr - mean) / std\n",
    "\n",
    "        lr = np.array([lr])\n",
    "        lr = tf.convert_to_tensor(lr)\n",
    "        vec1 = SRFECNN.predict(lr)\n",
    "        vec1 = vec1.flatten()\n",
    "        val[i] = vec1\n",
    "        val_labels[i] = int(i/2)\n",
    "        i += 1\n",
    "        \n",
    "    #STANDARDIZATION\n",
    "\n",
    "    for i in range(len(val[0])):\n",
    "        x = val[:,i]\n",
    "        x = x.astype('float32')\n",
    "        x = (x - mean_arr[i]) / std_arr[i]\n",
    "        val[:,i] = x\n",
    "    \n",
    "    sc_X = StandardScaler()\n",
    "    X_Train = sc_X.fit_transform(data)\n",
    "    X_val = sc_X.transform(val)\n",
    "\n",
    "    # Fitting the Logistic Regression into the Training set\n",
    "    classifier = LogisticRegression(max_iter=10**20)\n",
    "    classifier.fit(X_Train, train_labels)\n",
    "    \n",
    "    Y_Pred_train = classifier.predict(X_Train)\n",
    "    train_acc = accuracy_score(train_labels, Y_Pred_train)\n",
    "    train_acc_arr.append(train_acc)\n",
    "\n",
    "    Y_Pred = classifier.predict(X_val)\n",
    "    val_acc = accuracy_score(val_labels, Y_Pred)\n",
    "    val_acc_arr.append(val_acc)\n",
    "    \n",
    "    print(ite,train_acc_arr[ite],val_acc_arr[ite],train_loss[ite],val_loss[ite])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../train_loss.txt', 'w') as f:\n",
    "    for item in train_loss:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open('../val_loss.txt', 'w') as f:\n",
    "    for item in val_loss:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open('../train_acc.txt', 'w') as f:\n",
    "    for item in train_acc_arr:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open('../val_acc.txt', 'w') as f:\n",
    "    for item in val_acc_arr:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_acc_arr, label='Training Accuracy')\n",
    "plt.plot(val_acc_arr, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right', fontsize = 20)\n",
    "plt.ylabel('Accuracy', fontsize = 20)\n",
    "plt.xlabel('epoch', fontsize = 20)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right', fontsize = 20)\n",
    "plt.ylabel('Mean Squared Error', fontsize = 20)\n",
    "#plt.ylim([min(plt.ylim()),1])\n",
    "plt.ylim([0,7])\n",
    "plt.xlabel('epoch', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "start = time.time()\n",
    "i=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0\n",
    "accuracy = 0\n",
    "t=7.5\n",
    "b=0\n",
    "x = []\n",
    "def resolve_single(model, lr):\n",
    "    return resolve(model, tf.expand_dims(lr, axis=0))[0]\n",
    "#SRFECNN.load_weights('../../twobranch_extension/unfreezed15_lr=0.001.100-0.46.h5')\n",
    "for filename in os.listdir('../SRtrain/train'):\n",
    "    img = cv2.imread(os.path.join('../SRtrain/train',filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img = cv2.resize(img, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    #img = resolve_single(SR,img)\n",
    "    #img = np.array(img)\n",
    "    img = cv2.resize(img, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "    img = img.astype('float32')\n",
    "    mean, std = img.mean(), img.std()\n",
    "    img = (img - mean) / std\n",
    "    img = np.array([img])\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    vec = FECNN.predict(img)\n",
    "    #vec = vec/np.linalg.norm(vec)5\n",
    "    #print(vec)\n",
    "    #break\n",
    "    x.append(vec.flatten())\n",
    "    #vec1 = vec1/np.linalg.norm(vec1)\n",
    "    #a = []\n",
    "    '''for j in range(50):\n",
    "        k = 's' + str(j)\n",
    "        vec2 = dic[k]/np.linalg.norm(dic[k])\n",
    "        dist = tf.reduce_sum(K.sqrt(K.square(vec2-vec1)))\n",
    "        a.append(dist)'''  \n",
    "#print(x)\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "fig = plt.figure(figsize = (6,5))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "#plt.ylim([-30,30])\n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "#ax.set_title('2 Component PCA - 10 subjects', fontsize = 20)\n",
    "colors = ['r', 'g', 'b','c','m','y','k','gold','grey','purple']\n",
    "k=[0,2,6,8,9]\n",
    "x = 10\n",
    "for i in range(10):\n",
    "    ax.scatter(principalDf.loc[range((i*x),((i*x)+x)), 'principal component 1']\n",
    "               , principalDf.loc[range((i*x),((i*x)+x)), 'principal component 2']\n",
    "               , c = colors[i]\n",
    "               , s = 40)\n",
    "#ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf = pd.DataFrame(data = test2d\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "#plt.ylim([-30,30])\n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('FECNN Features PCA', fontsize = 20)\n",
    "colors = ['r', 'g', 'b','c','m','y','k','gold','grey','purple']\n",
    "k=[0,2,6,8,9]\n",
    "x = 5\n",
    "for i in range(10):\n",
    "    ax.scatter(principalDf.loc[range((i*x),((i*x)+x)), 'principal component 1']\n",
    "               , principalDf.loc[range((i*x),((i*x)+x)), 'principal component 2']\n",
    "               , c = colors[i]\n",
    "               , s = 50)\n",
    "#ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean = KMeans(n_clusters=2)\n",
    "labels = kmean.fit_predict(b)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_1=[]\n",
    "labels_0=[]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i]==1):\n",
    "        labels_1.append(b[i])\n",
    "    else:\n",
    "        labels_0.append(b[i])\n",
    "print(len(labels_1))\n",
    "print(len(labels_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(0,1)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Image number', fontsize = 15)\n",
    "ax.set_ylabel('Distance', fontsize = 15)\n",
    "ax.set_title('KMeans clustering', fontsize = 20)\n",
    "ax.scatter(range(0,56),labels_0,color='red')\n",
    "ax.scatter(range(56,100),labels_1,color='blue')\n",
    "ax.scatter([20,53],[[0.37287224],\n",
    "       [0.11982424]],marker='x',linewidths=3,color='purple')\n",
    "ax.plot([0,66],[0.235,0.235],color='green')\n",
    "ax.legend(['Threshold','Img not in DB','Img in DB','Cluster centroids'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b[:40]\n",
    "mini = min(c)\n",
    "#print(mini)\n",
    "d = b[40:]\n",
    "maxi = max(d)\n",
    "#print(c) maximum = 0.23314758\n",
    "print(d) #minimum = 0.23771875,0.25001103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "classifier_model = tf.keras.models.Sequential()\n",
    "classifier_model.add(tf.keras.layers.Dense(195, input_shape = (512,), activation = 'softmax'))#tfa.activations.mish))\n",
    "#classifier_model.add(tf.keras.layers.Dropout(0.5))\n",
    "#classifier_model.add(tf.keras.layers.Dense(195, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier_model = build_classifier_model()\n",
    "opt = optimizers.Adam()\n",
    "classifier_model.compile(optimizer='adam',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh_labels = tf.one_hot(train_labels, 195)\n",
    "val_oh_labels = tf.one_hot(val_labels, 195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                              patience=5, min_lr=0.000001)\n",
    "history = classifier_model.fit(x = data, y = train_oh_labels, validation_data = (val, val_oh_labels), batch_size=1950, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_model.predict(test)\n",
    "pred = [np.argmax(x) for x in y_pred]\n",
    "test_acc = accuracy_score(test_labels, pred)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_Train = sc_X.fit_transform(data)\n",
    "X_Test = sc_X.transform(val)\n",
    "\n",
    "# Fitting the Logistic Regression into the Training set\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = LogisticRegression(solver = 'lbfgs', max_iter=10**20)\n",
    "classifier.fit(X_Train, train_labels)\n",
    "\n",
    "# Predicting the test set results\n",
    "\n",
    "Y_Pred = classifier.predict(X_Test)\n",
    "\n",
    "# Making the Confusion Matrix \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(val_labels, Y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  1.0\n",
      "Val Accuracy:  0.9401913875598086\n"
     ]
    }
   ],
   "source": [
    "#print(Y_Pred)\n",
    "X_Test = sc_X.transform(data)\n",
    "Y_Pred_train = classifier.predict(X_Test)\n",
    "test_acc = accuracy_score(train_labels, Y_Pred_train)\n",
    "print(\"Train Accuracy: \", test_acc)\n",
    "\n",
    "X_Test = sc_X.transform(val)\n",
    "Y_Pred = classifier.predict(X_Test)\n",
    "test_acc = accuracy_score(val_labels, Y_Pred)\n",
    "print(\"Val Accuracy: \", test_acc)\n",
    "\n",
    "#shuffled = np.zeros((300,513))\n",
    "#shuffled[:,:512] = test\n",
    "#shuffled[:,512] = test_labels\n",
    "#np.random.shuffle(shuffled)\n",
    "#test_shuffled = shuffled[:,:512]\n",
    "#labels_shuffled = shuffled[:,512]\n",
    "#X_Test = sc_X.transform(test)\n",
    "#Y_Pred = classifier.predict(X_Test)\n",
    "#test_acc = accuracy_score(test_labels, Y_Pred)\n",
    "#print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9665071770334929\n"
     ]
    }
   ],
   "source": [
    "X_Test = sc_X.transform(test)\n",
    "Y_Pred = classifier.predict(X_Test)\n",
    "test_acc = accuracy_score(test_labels, Y_Pred)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = sc_X.transform(test)\n",
    "pred_proba_df = classifier.predict_proba(X_Test)\n",
    "print(pred_proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred = classifier.predict(X_Test)\n",
    "threshold_list = []\n",
    "x=0\n",
    "while x<=1:\n",
    "    threshold_list.append(x)\n",
    "    x += 0.001\n",
    "    \n",
    "print(len(threshold_list))\n",
    "Y_test_pred = np.zeros((1227,))\n",
    "for i in threshold_list:\n",
    "    print ('\\n******** For i = {} ******'.format(i))\n",
    "    for j in range(1227):\n",
    "        prob = max(pred_proba_df[j])\n",
    "        if prob < i:\n",
    "            Y_test_pred[j] = -1\n",
    "        else:\n",
    "            Y_test_pred[j] = Y_Pred[j]\n",
    "        \n",
    "    \n",
    "    test_accuracy = accuracy_score(test_labels,Y_test_pred)\n",
    "    print('Our testing accuracy is {}'.format(test_accuracy))\n",
    "\n",
    "    #print(confusion_matrix(test_labels.as_matrix().reshape(test_labels.as_matrix().size,1),\n",
    "    #                       Y_test_pred.iloc[:,1].as_matrix().reshape(Y_test_pred.iloc[:,1].as_matrix().size,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()\n",
    "import mtcnn\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "def process(pixels):\n",
    "    global flag\n",
    "    results = detector.detect_faces(pixels)\n",
    "    if len(results) == 0:\n",
    "        flag = 1\n",
    "        return 0\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    img = pixels[y1:y2, x1:x2]\n",
    "    img = cv2.resize(img, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n",
    "test_labels = np.zeros((10,))\n",
    "b = []\n",
    "i=0\n",
    "test = np.zeros((10,512))\n",
    "for filename in os.listdir('../../../test'):\n",
    "    lr = cv2.imread(os.path.join('../../../test',filename))\n",
    "    lr = process(lr)\n",
    "    lr = cv2.cvtColor(lr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    lr = cv2.resize(lr, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    lr = resolve_single(SR, lr)\n",
    "    lr = np.array(lr)\n",
    "    lr = cv2.resize(lr, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    lr = lr.astype('float32')\n",
    "    mean, std = lr.mean(), lr.std()\n",
    "    lr = (lr - mean) / std\n",
    "    \n",
    "    lr = np.array([lr])\n",
    "    lr = tf.convert_to_tensor(lr)\n",
    "    vec1 = SRFECNN.predict(lr)\n",
    "    vec1 = vec1.flatten() \n",
    "    test[i] = vec1\n",
    "    #test_labels[i] = int(i/5)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARDIZATION\n",
    "\n",
    "for i in range(len(test[0])):\n",
    "    x = test[:,i]\n",
    "    x = x.astype('float32')\n",
    "    x = (x - mean_arr[i]) / std_arr[i]\n",
    "    test[:,i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = [98,98,98,98,98,99,99,99,99,99]\n",
    "print(np.array(test_labels))\n",
    "os.listdir('../../../test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRFECNN.load_weights('../twobranch_extension/209_subjects/24,24_bicubic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "j=1\n",
    "temp = []\n",
    "data = np.zeros((1950,512))\n",
    "train_labels = np.zeros((1950,))\n",
    "for filename in os.listdir('../low-res-face-recognition/Dataset/final_gen_data/train'):\n",
    "    hr = cv2.imread(os.path.join('../low-res-face-recognition/Dataset/final_gen_data/train',filename))\n",
    "    hr = cv2.cvtColor(hr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    hr = hr.astype('float32')\n",
    "    mean, std = hr.mean(), hr.std()\n",
    "    hr = (hr - mean) / std\n",
    "    hr = np.array([hr])\n",
    "    hr = tf.convert_to_tensor(hr)\n",
    "    vec = FECNN.predict(hr)\n",
    "    vec = vec.flatten()\n",
    "    data[i] = vec\n",
    "    train_labels[i] = int(i/10)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_single(model, lr):\n",
    "    return resolve(model, tf.expand_dims(lr, axis=0))[0]\n",
    "i=0\n",
    "j=1\n",
    "temp = []\n",
    "data = np.zeros((2090,512))\n",
    "train_labels = np.zeros((2090,))\n",
    "for filename in os.listdir('../final_gen_data_209/train'):\n",
    "    lr = cv2.imread(os.path.join('../final_gen_data_209/train',filename))\n",
    "    lr = cv2.cvtColor(lr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    lr = cv2.resize(lr, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    #lr = resolve_single(SR, lr)\n",
    "    lr = resolve_single(pre_generator, lr)\n",
    "    lr = resolve_single(gan_generator, lr)\n",
    "    lr = np.array(lr)\n",
    "    lr = cv2.resize(lr, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    lr = lr.astype('float32')\n",
    "    mean, std = lr.mean(), lr.std()\n",
    "    lr = (lr - mean) / std\n",
    "    \n",
    "    lr = np.array([lr])\n",
    "    lr = tf.convert_to_tensor(lr)\n",
    "    vec1 = SRFECNN.predict(lr)\n",
    "    vec1 = vec1.flatten() \n",
    "    data[i] = vec1\n",
    "    train_labels[i] = int(i/10)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARDIZATION\n",
    "\n",
    "mean_arr = []\n",
    "std_arr = []\n",
    "for i in range(len(data[0])):\n",
    "    x = data[:,i]\n",
    "    x = x.astype('float32')\n",
    "    mean, std = x.mean(), x.std()\n",
    "    x = (x - mean) / std\n",
    "    mean_arr.append(mean)\n",
    "    std_arr.append(std)\n",
    "    data[:,i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "j=1\n",
    "temp = []\n",
    "val = np.zeros((390,512))\n",
    "val_labels = np.zeros((390,))\n",
    "for filename in os.listdir('../low-res-face-recognition/Dataset/final_gen_data/val'):\n",
    "    hr = cv2.imread(os.path.join('../low-res-face-recognition/Dataset/final_gen_data/val',filename))\n",
    "    hr = cv2.cvtColor(hr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    hr = hr.astype('float32')\n",
    "    mean, std = hr.mean(), hr.std()\n",
    "    hr = (hr - mean) / std\n",
    "    hr = np.array([hr])\n",
    "    hr = tf.convert_to_tensor(hr)\n",
    "    vec = FECNN.predict(hr)\n",
    "    vec = vec.flatten()\n",
    "    val[i] = vec\n",
    "    val_labels[i] = int(i/2)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "j=1\n",
    "temp = []\n",
    "val = np.zeros((418,512))\n",
    "val_labels = np.zeros((418,))\n",
    "for filename in os.listdir('../final_gen_data_209/val'):\n",
    "    lr = cv2.imread(os.path.join('../final_gen_data_209/val',filename))\n",
    "    lr = cv2.cvtColor(lr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    lr = cv2.resize(lr, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    #lr = resolve_single(SR, lr)\n",
    "    lr = resolve_single(pre_generator, lr)\n",
    "    lr = resolve_single(gan_generator, lr)\n",
    "    lr = np.array(lr)\n",
    "    lr = cv2.resize(lr, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    lr = lr.astype('float32')\n",
    "    mean, std = lr.mean(), lr.std()\n",
    "    lr = (lr - mean) / std\n",
    "    \n",
    "    lr = np.array([lr])\n",
    "    lr = tf.convert_to_tensor(lr)\n",
    "    vec1 = SRFECNN.predict(lr)\n",
    "    vec1 = vec1.flatten()\n",
    "    val[i] = vec1\n",
    "    val_labels[i] = int(i/2)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARDIZATION\n",
    "\n",
    "for i in range(len(val[0])):\n",
    "    x = val[:,i]\n",
    "    x = x.astype('float32')\n",
    "    x = (x - mean_arr[i]) / std_arr[i]\n",
    "    val[:,i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.zeros((1227,))\n",
    "b = []\n",
    "i=0\n",
    "test = np.zeros((1227,512))\n",
    "for filename in os.listdir('../final_gen_data_209/test'):\n",
    "    lr = cv2.imread(os.path.join('../final_gen_data_209/test',filename))\n",
    "    lr = cv2.cvtColor(lr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    lr = cv2.resize(lr, (36,36), interpolation=cv2.INTER_CUBIC)\n",
    "    #lr = resolve_single(SR, lr)\n",
    "    #lr = np.array(lr)\n",
    "    lr = cv2.resize(lr, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    lr = lr.astype('float32')\n",
    "    mean, std = lr.mean(), lr.std()\n",
    "    lr = (lr - mean) / std\n",
    "    \n",
    "    lr = np.array([lr])\n",
    "    lr = tf.convert_to_tensor(lr)\n",
    "    vec1 = SRFECNN.predict(lr)\n",
    "    vec1 = vec1.flatten() \n",
    "    test[i] = vec1\n",
    "    if i < 627:\n",
    "        test_labels[i] = int(i/3)\n",
    "    else:\n",
    "        test_labels[i] = -1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.zeros((627,))\n",
    "b = []\n",
    "i=0\n",
    "test = np.zeros((627,512))\n",
    "for filename in os.listdir('../low-res-face-recognition/Dataset/final_gen_data_209/test'):\n",
    "    lr = cv2.imread(os.path.join('../low-res-face-recognition/Dataset/final_gen_data_209/test',filename))\n",
    "    lr = cv2.cvtColor(lr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    lr = cv2.resize(lr, (24,24), interpolation=cv2.INTER_CUBIC)\n",
    "    #lr = resolve_single(SR, lr)\n",
    "    lr = resolve_single(pre_generator, lr)\n",
    "    lr = resolve_single(gan_generator, lr)\n",
    "    lr = np.array(lr)\n",
    "    lr = cv2.resize(lr, (160,160), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    lr = lr.astype('float32')\n",
    "    mean, std = lr.mean(), lr.std()\n",
    "    lr = (lr - mean) / std\n",
    "    \n",
    "    lr = np.array([lr])\n",
    "    lr = tf.convert_to_tensor(lr)\n",
    "    vec1 = SRFECNN.predict(lr)\n",
    "    vec1 = vec1.flatten() \n",
    "    test[i] = vec1\n",
    "\n",
    "    test_labels[i] = int(i/3)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARDIZATION\n",
    "\n",
    "for i in range(len(test[0])):\n",
    "    x = test[:,i]\n",
    "    x = x.astype('float32')\n",
    "    x = (x - mean_arr[i]) / std_arr[i]\n",
    "    test[:,i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = svm.SVC(kernel = 'linear', gamma='scale', probability = True) \n",
    "svc_model.fit(data, train_labels)\n",
    "\n",
    "## Train Accuracy\n",
    "pred = svc_model.predict(data)\n",
    "train_acc = accuracy_score(train_labels, pred)\n",
    "print(\"Training Accuracy: \", train_acc)\n",
    "\n",
    "## Test Accuracy\n",
    "pred = svc_model.predict(test)\n",
    "test_acc = accuracy_score(test_labels, pred)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=20)\n",
    "model.fit(data, train_labels)\n",
    "\n",
    "## Train Accuracy\n",
    "pred = model.predict(data)\n",
    "train_acc = accuracy_score(train_labels, pred)\n",
    "print(\"Training Accuracy: \", train_acc)\n",
    "\n",
    "pred = model.predict(test)\n",
    "test_acc = accuracy_score(test_labels, pred)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#dataset = datasets.load_iris()\n",
    "\n",
    "model = SVC(kernel = 'linear',probability = True)\n",
    "model.fit(data, labels)\n",
    "print(model)\n",
    "\n",
    "#expected = dataset.target\n",
    "#predicted = model.predict(dataset.data)\n",
    "\n",
    "#print(metrics.classification_report(expected, predicted))\n",
    "#print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1 = np.linalg.norm(data[3] - test[1])\n",
    "dist2 = np.linalg.norm(data[3] - test[10])\n",
    "print(dist1,dist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = svc_model.predict(test)\n",
    "print(metrics.classification_report(test_labels, predicted))\n",
    "print(metrics.confusion_matrix(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = StandardScaler().fit_transform(data)\n",
    "pca = PCA(n_components=2)\n",
    "data2d = pca.fit_transform(x)\n",
    "\n",
    "x = StandardScaler().fit_transform(test)\n",
    "pca = PCA(n_components=2)\n",
    "test2d = pca.fit_transform(x)\n",
    "#print(principalComponents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2d[:,0] *= -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test2d[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "\n",
    "# import some data to play with\n",
    "\n",
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "X = data2d\n",
    "y = train_labels\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 1.0  # SVM regularization parameter\n",
    "models = (svm.SVC(kernel='linear', C=C),\n",
    "          svm.LinearSVC(C=C, max_iter=10000),\n",
    "          svm.SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "          svm.SVC(kernel='poly', degree=3, gamma='auto', C=C))\n",
    "models = (clf.fit(X, y) for clf in models)\n",
    "\n",
    "# title for the plots\n",
    "titles = ('SVC with linear kernel',\n",
    "          'LinearSVC (linear kernel)',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel')\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "X0, X1 = X[:, 0], X[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    plot_contours(ax, clf, xx, yy,\n",
    "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('Sepal length')\n",
    "    ax.set_ylabel('Sepal width')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
